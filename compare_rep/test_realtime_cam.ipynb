{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[5455]: Class CaptureDelegate is implemented in both /Users/winirrr/pytorch-test/env/lib/python3.9/site-packages/dv_processing.dylibs/libopencv_videoio.4.8.0.dylib (0x109d00880) and /Users/winirrr/pytorch-test/env/lib/libopencv_videoio.4.6.0.dylib (0x11dec9240). One of the two will be used. Which one is undefined.\n"
     ]
    }
   ],
   "source": [
    "import dv_processing as dv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from datetime import timedelta\n",
    "from models.cnn_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device discovery: found 1 devices.\n",
      "Detected device [DVXplorer_DXA00417]\n"
     ]
    }
   ],
   "source": [
    "import dv_processing as dv\n",
    "\n",
    "cameras = dv.io.discoverDevices()\n",
    "\n",
    "print(f\"Device discovery: found {len(cameras)} devices.\")\n",
    "for camera_name in cameras:\n",
    "    print(f\"Detected device [{camera_name}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open any camera\n",
    "capture = dv.io.CameraCapture(cameraName=\"DVXplorer_DXA00417\")\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize the images if needed\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),         # Convert images to tensor\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])  # Normalize\n",
    "])\n",
    "\n",
    "# Device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load pre-trained model\n",
    "loaded_model = LeNet()\n",
    "loaded_model.load_state_dict(torch.load(\"/Users/winirrr/Documents/EventBased_Project/models_save/dv_df_11ms_aug_LeNet_0.pth\"))\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "predicted_class = {0:\"no_press\",\n",
    "                   1:\"press\"}\n",
    "\n",
    "# Initialize an accumulator with some resolution\n",
    "accumulator = dv.Accumulator(capture.getEventResolution())\n",
    "\n",
    "# Apply configuration, these values can be modified to taste\n",
    "accumulator.setMinPotential(0.0)\n",
    "accumulator.setMaxPotential(1.0)\n",
    "accumulator.setNeutralPotential(0.5)\n",
    "accumulator.setEventContribution(0.15)\n",
    "accumulator.setDecayFunction(dv.Accumulator.Decay.EXPONENTIAL)\n",
    "accumulator.setDecayParam(1e+6)\n",
    "accumulator.setIgnorePolarity(False)\n",
    "accumulator.setSynchronousDecay(True)\n",
    "\n",
    "slicer = dv.EventStreamSlicer()\n",
    "\n",
    "def slicing_callback(events: dv.EventStore):\n",
    "    accumulator.accept(events)\n",
    "    frame = accumulator.generateFrame()\n",
    "    preview = cv2.cvtColor(frame.image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "\n",
    "    # Preprocess the frame for the model\n",
    "    pil_image = Image.fromarray(frame.image)\n",
    "    input_tensor = transform(pil_image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = loaded_model(input_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        prediction = predicted.item()\n",
    "        # print(prediction)\n",
    "\n",
    "    # Put prediction text on the frame\n",
    "    cv2.putText(preview, f'Prediction: {predicted_class[prediction]}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Show the accumulated image\n",
    "    cv2.imshow(\"Preview\", preview)\n",
    "    # cv2.waitKey(2)\n",
    "\n",
    "slicer.doEveryTimeInterval(timedelta(milliseconds=11), slicing_callback)\n",
    "\n",
    "\n",
    "# Run the loop while camera is still connected\n",
    "while capture.isRunning():\n",
    "    # Read batch of events\n",
    "    events = capture.getNextEventBatch()\n",
    "    # The method does not wait for data arrive, it returns immediately with\n",
    "    # latest available data or if no data is available, returns a `None`\n",
    "    if events is not None:\n",
    "        # Print received packet time range\n",
    "        slicer.accept(events)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    # else:\n",
    "    #     # No data has arrived yet, short sleep to reduce CPU load\n",
    "    #     time.sleep(0.001)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
