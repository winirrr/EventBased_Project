{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Event Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_synthetic_events(num_events, sensor_width, sensor_height):\n",
    "    timestamps = np.random.uniform(0, 1, num_events)\n",
    "    x_coords = np.random.randint(0, sensor_width, num_events)\n",
    "    y_coords = np.random.randint(0, sensor_height, num_events)\n",
    "    polarities = np.random.choice([-1, 1], num_events)\n",
    "    events = np.vstack((timestamps, x_coords, y_coords, polarities)).T\n",
    "    return events\n",
    "\n",
    "def normalize_events(events, sensor_width, sensor_height):\n",
    "    min_t, max_t = events[:, 0].min(), events[:, 0].max()\n",
    "    events[:, 0] = (events[:, 0] - min_t) / (max_t - min_t)\n",
    "    events[:, 1] = events[:, 1] / sensor_width\n",
    "    events[:, 2] = events[:, 2] / sensor_height\n",
    "    return events\n",
    "\n",
    "# Generate synthetic events\n",
    "num_events = 1000\n",
    "sensor_width = 240\n",
    "sensor_height = 180\n",
    "events = generate_synthetic_events(num_events, sensor_width, sensor_height)\n",
    "\n",
    "# Normalize events\n",
    "normalized_events = normalize_events(events, sensor_width, sensor_height)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Modify the Network to Handle Event Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIFNeuronLayer:\n",
    "    def __init__(self, num_neurons, tau_m, V_rest, V_thresh, V_reset, R, dt):\n",
    "        self.num_neurons = num_neurons\n",
    "        self.tau_m = tau_m\n",
    "        self.V_rest = V_rest\n",
    "        self.V_thresh = V_thresh\n",
    "        self.V_reset = V_reset\n",
    "        self.R = R\n",
    "        self.dt = dt\n",
    "        self.V = np.full(num_neurons, V_rest)\n",
    "        self.spikes = np.zeros(num_neurons)\n",
    "\n",
    "    def update(self, I):\n",
    "        dV = (-(self.V - self.V_rest) + self.R * I) * (self.dt / self.tau_m)\n",
    "        self.V += dV\n",
    "\n",
    "        self.spikes = self.V >= self.V_thresh\n",
    "        self.V[self.spikes] = self.V_reset\n",
    "    \n",
    "    def reset(self):\n",
    "        self.V = np.full(self.num_neurons, self.V_rest)\n",
    "        self.spikes = np.zeros(self.num_neurons)\n",
    "\n",
    "class SpikingNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, tau_m, V_rest, V_thresh, V_reset, R, dt):\n",
    "        self.input_layer = np.zeros(input_size)\n",
    "        self.hidden_layer = LIFNeuronLayer(hidden_size, tau_m, V_rest, V_thresh, V_reset, R, dt)\n",
    "        self.output_layer = LIFNeuronLayer(output_size, tau_m, V_rest, V_thresh, V_reset, R, dt)\n",
    "        \n",
    "        self.W_input_hidden = np.random.normal(0, 1, (hidden_size, input_size))\n",
    "        self.W_hidden_output = np.random.normal(0, 1, (output_size, hidden_size))\n",
    "\n",
    "    def forward(self, input_spikes):\n",
    "        self.input_layer = input_spikes\n",
    "\n",
    "        I_hidden = self.W_input_hidden @ self.input_layer\n",
    "        self.hidden_layer.update(I_hidden)\n",
    "\n",
    "        I_output = self.W_hidden_output @ self.hidden_layer.spikes\n",
    "        self.output_layer.update(I_output)\n",
    "\n",
    "    def reset(self):\n",
    "        self.hidden_layer.reset()\n",
    "        self.output_layer.reset()\n",
    "\n",
    "def events_to_input(events, num_neurons, T, dt):\n",
    "    time_steps = int(T / dt)\n",
    "    input_spikes = np.zeros((num_neurons, time_steps))\n",
    "\n",
    "    for event in events:\n",
    "        t_event = event[0] * T  # Scale event time to simulation duration\n",
    "        neuron_idx = int(event[1] * num_neurons)\n",
    "        time_idx = int(t_event / dt)\n",
    "\n",
    "        # Ensure indices are within bounds\n",
    "        if neuron_idx >= num_neurons:\n",
    "            neuron_idx = num_neurons - 1\n",
    "        if time_idx >= time_steps:\n",
    "            time_idx = time_steps - 1\n",
    "\n",
    "        input_spikes[neuron_idx, time_idx] += event[3]  # Polarity as spike contribution\n",
    "\n",
    "    return input_spikes\n",
    "\n",
    "\n",
    "# Parameters\n",
    "tau_m = 20e-3  # Membrane time constant\n",
    "V_rest = -70e-3  # Resting potential\n",
    "V_thresh = -50e-3  # Threshold potential\n",
    "V_reset = -80e-3  # Reset potential\n",
    "R = 1e7  # Membrane resistance\n",
    "dt = 1e-4  # Time step\n",
    "T = 1.0  # 1 second simulation\n",
    "\n",
    "num_neurons_input = 240  # Number of input neurons (same as sensor width)\n",
    "num_neurons_hidden = 100  # Number of hidden neurons\n",
    "num_neurons_output = 3  # Number of output neurons (classes)\n",
    "\n",
    "# Create synthetic event data for training\n",
    "num_samples = 100\n",
    "data = [normalize_events(generate_synthetic_events(num_events, sensor_width, sensor_height), sensor_width, sensor_height) for _ in range(num_samples)]\n",
    "labels = np.random.randint(0, num_neurons_output, num_samples)\n",
    "\n",
    "# Convert event data to input spikes\n",
    "input_spikes_data = [events_to_input(events, num_neurons_input, T, dt) for events in data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 completed.\n",
      "Epoch 2/10 completed.\n",
      "Epoch 3/10 completed.\n",
      "Epoch 4/10 completed.\n",
      "Epoch 5/10 completed.\n",
      "Epoch 6/10 completed.\n",
      "Epoch 7/10 completed.\n",
      "Epoch 8/10 completed.\n",
      "Epoch 9/10 completed.\n",
      "Epoch 10/10 completed.\n"
     ]
    }
   ],
   "source": [
    "def train(network, data, labels, num_epochs, learning_rate):\n",
    "    for epoch in range(num_epochs):\n",
    "        for input_spikes, label in zip(data, labels):\n",
    "            network.reset()\n",
    "            for t in range(input_spikes.shape[1]):\n",
    "                network.forward(input_spikes[:, t])\n",
    "\n",
    "            target_spikes = np.zeros(network.output_layer.num_neurons)\n",
    "            target_spikes[label] = 1\n",
    "\n",
    "            dW_hidden_output = learning_rate * (target_spikes - network.output_layer.spikes).reshape(-1, 1) @ network.hidden_layer.spikes.reshape(1, -1)\n",
    "            network.W_hidden_output += dW_hidden_output\n",
    "\n",
    "            dW_input_hidden = learning_rate * (network.hidden_layer.spikes.reshape(-1, 1) @ input_spikes[:, t].reshape(1, -1))\n",
    "            network.W_input_hidden += dW_input_hidden\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs} completed.')\n",
    "\n",
    "# Create and train the network\n",
    "network = SpikingNeuralNetwork(num_neurons_input, num_neurons_hidden, num_neurons_output, tau_m, V_rest, V_thresh, V_reset, R, dt)\n",
    "train(network, input_spikes_data, labels, num_epochs=10, learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 30.00%\n"
     ]
    }
   ],
   "source": [
    "def evaluate(network, data, labels):\n",
    "    correct = 0\n",
    "    total = len(labels)\n",
    "\n",
    "    for input_spikes, label in zip(data, labels):\n",
    "        network.reset()\n",
    "        for t in range(input_spikes.shape[1]):\n",
    "            network.forward(input_spikes[:, t])\n",
    "\n",
    "        predicted_label = np.argmax(network.output_layer.spikes)\n",
    "        if predicted_label == label:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Create synthetic event data for testing\n",
    "test_data = [normalize_events(generate_synthetic_events(num_events, sensor_width, sensor_height), sensor_width, sensor_height) for _ in range(num_samples)]\n",
    "test_labels = np.random.randint(0, num_neurons_output, num_samples)\n",
    "\n",
    "# Convert event data to input spikes for testing\n",
    "test_input_spikes_data = [events_to_input(events, num_neurons_input, T, dt) for events in test_data]\n",
    "\n",
    "# Evaluate the network\n",
    "evaluate(network, test_input_spikes_data, test_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
